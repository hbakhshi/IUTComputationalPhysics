{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f9c02f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c08a2aab",
   "metadata": {},
   "source": [
    "# طراحی و آموزش شبکه‌ی عصبی کانولوشنی (CNN) برای طبقه‌بندی جت‌های WZ و QCD\n",
    "\n",
    "در این بخش قصد داریم از **شبکه‌های عصبی کانولوشنی (CNN)** برای **طبقه‌بندی جت‌های حاصل از فرایندهای WZ و QCD** استفاده کنیم.\n",
    "\n",
    "### 🎯 هدف\n",
    "\n",
    "هدف اصلی ما این است که شبکه یاد بگیرد تفاوت ساختاری بین جت‌های حاصل از فرآیند W → jj (در WZ) و جت‌های QCD (حاصل از کوارک یا گلئون) را شناسایی کند. از آنجایی که ساختار جت‌ها حاوی اطلاعاتی درباره منشأ آن‌ها است، ما از آن بهره می‌گیریم.\n",
    "\n",
    "### 🗺️ نمایش جت به‌صورت تصویر\n",
    "\n",
    "برای استفاده از CNN، نیاز داریم که داده‌های ورودی را به فرم تصویر درآوریم. ما از **مختصات η (اتا) و φ (فی)** برای ایجاد یک شبکه دوبعدی استفاده می‌کنیم. در این نقشه:\n",
    "\n",
    "- محور افقی: φ (زاویه قطبی حول محور پرتو)\n",
    "- محور عمودی: η (متغیر مربوط به زاویه ضربه ذره نسبت به محور پرتو)\n",
    "- شدت (رنگ پیکسل): میزان `pt` ذره در آن سلول (به‌صورت وزن‌شده)\n",
    "\n",
    "به این ترتیب، **برای هر جت یک \"نقشه حرارتی (heatmap)\" از توزیع انرژی ذرات در فضای η–φ خواهیم داشت**.\n",
    "\n",
    "### 🧱 داده‌های ورودی\n",
    "\n",
    "- ما از داده‌های HDF5 استفاده می‌کنیم که در مقاله [RODEM – arXiv:2408.11616](https://arxiv.org/abs/2408.11616) آمده‌اند.\n",
    "- مؤلفه‌های جت اول (`jet1_cnsts`) را استخراج می‌کنیم.\n",
    "- برای هر ایونت، یک تصویر ۲بعدی با اندازه ثابت (مثلاً 100x100) تولید می‌کنیم که نشان‌دهنده توزیع `pt` در η–φ است.\n",
    "- لیبل `0` برای کلاس QCD و لیبل `1` برای کلاس WZ استفاده خواهد شد.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c44466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219493a8",
   "metadata": {},
   "source": [
    "### دانلود و آماده سازی داده ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "filename = 'CPHdata.tar.gz'\n",
    "\n",
    "# دانلود فایل\n",
    "print('Downloading...')\n",
    "urllib.request.urlretrieve(\"https://hbakhshi.web.cern.ch/hbakhshi/IUT/TMP/CPHdata.tar.gz\", filename)\n",
    "print('Download completed.')\n",
    "\n",
    "# استخراج فایل tar.gz\n",
    "print('Extracting...')\n",
    "with tarfile.open(filename, 'r:gz') as tar:\n",
    "    tar.extractall(path=\".\")\n",
    "print('Extraction completed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18724cc",
   "metadata": {},
   "source": [
    "## ⚙️ تنظیمات پروژه تشخیص جت با CNN در فضای η–φ\n",
    "\n",
    "در این بخش، ما تنظیمات اولیه‌ی پروژه‌ی یادگیری ماشین برای طبقه‌بندی جت‌های حاصل از فرایندهای WZ (سیگنال) و QCD (پس‌زمینه) را تعریف می‌کنیم. این تنظیمات شامل مسیر داده‌ها، ابعاد تصاویر، پارامترهای آموزش، و تعریف GPU/CPU هستند.\n",
    "\n",
    "### ⚙️ جزئیات پارامترهای `Config`\n",
    "\n",
    "کلاس `Config` نقش ستون فقرات تنظیمات پروژه را ایفا می‌کند. در این کلاس، مسیر داده‌ها، ویژگی‌های مدل، و تنظیمات آموزش مشخص می‌شوند.\n",
    "\n",
    "| نام پارامتر        | مقدار نمونه                              | توضیح کامل |\n",
    "|-------------------|------------------------------------------|------------|\n",
    "| `SIGNALS_PATH`    | `'./'`                                   | مسیر دایرکتوری فایل‌های **سیگنال** (مانند WZ) |\n",
    "| `BKG_PATH`        | `'./'`                                   | مسیر فایل‌های **پس‌زمینه** (مانند QCD) |\n",
    "| `SIGNALS`         | `['WZ_jjnunu_pT_450_1200_test.h5']`      | لیستی از فایل‌های مربوط به داده‌های **سیگنال** |\n",
    "| `BKGS`            | `['QCDjj_pT_450_1200_test.h5']`          | لیستی از فایل‌های مربوط به داده‌های **پس‌زمینه** |\n",
    "| `IMAGE_SIZE`      | `32`                                     | ابعاد تصویر تولیدشده از داده‌ها در صفحه‌ی η–φ به‌صورت `IMAGE_SIZE × IMAGE_SIZE` |\n",
    "| `BATCH_SIZE`      | `64`                                     | تعداد تصاویر در هر دسته (Batch) در طول آموزش |\n",
    "| `EPOCHS`          | `10`                                     | تعداد تکرار آموزش روی کل داده‌ها |\n",
    "| `LR`              | `1e-3`                                   | نرخ یادگیری (Learning Rate) برای به‌روزرسانی وزن‌ها |\n",
    "| `NUM_CLASSES`     | `2`                                      | تعداد کلاس‌ها برای طبقه‌بندی (۰ = QCD، ۱ = WZ) |\n",
    "| `DEVICE`          | `torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")` | به‌صورت خودکار مشخص می‌کند که از GPU استفاده شود یا CPU (اگر GPU در دسترس باشد، استفاده می‌شود) |\n",
    "\n",
    "---\n",
    "\n",
    "🎯 **نکته:**  \n",
    "با استفاده از کلاس `Config` می‌توانیم تغییرات اصلی پروژه را تنها با ویرایش یک محل انجام دهیم؛ این باعث ساختار بهتر، نگهداری آسان‌تر، و قابلیت بازاستفاده بالا می‌شود.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01696dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    SIGNALS_PATH = './'\n",
    "    BKG_PATH = './'\n",
    "    SIGNALS = ['mini_WZ_jjnunu_pT_450_1200_test.h5']\n",
    "    BKGS = ['mini_QCDjj_pT_450_1200_test.h5']\n",
    "    IMAGE_SIZE = 32\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 10\n",
    "    LR = 1e-3\n",
    "    NUM_CLASSES = 2        \n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb7de3",
   "metadata": {},
   "source": [
    "## 📂 توابع کمکی برای بارگذاری مسیر فایل‌ها و برچسب‌ها\n",
    "\n",
    "### 🔧 `AllFiles()` — لیست مسیر کامل فایل‌ها\n",
    "\n",
    "این تابع مسیر کامل تمام فایل‌های HDF5 را بازمی‌گرداند. فایل‌ها از دو نوع سیگنال (مانند WZ) و پس‌زمینه (مانند QCD) هستند.\n",
    "\n",
    "#### 📥 ورودی:\n",
    "- بدون ورودی خارجی – فایل‌ها بر اساس مقادیر تعریف‌شده در کلاس `Config` بارگذاری می‌شوند.\n",
    "\n",
    "#### 📤 خروجی:\n",
    "- لیستی از مسیرهای کامل فایل‌ها از هر دو مجموعه‌ی `SIGNALS` و `BKGS`.\n",
    "\n",
    "#### 🧠 منطق:\n",
    "1. برای هر فایل در `Config.SIGNALS`، مسیر آن به کمک `Path` به `Config.SIGNALS_PATH` الصاق می‌شود.\n",
    "2. برای هر فایل در `Config.BKGS`، مسیر آن به `Config.BKG_PATH` الصاق می‌شود.\n",
    "3. ترکیب نهایی مسیرها (Signals + Backgrounds) به عنوان خروجی بازگردانده می‌شود.\n",
    "---\n",
    "\n",
    "## 🏷️ تابع `GetLabels()` — تولید برچسب کلاس برای هر فایل\n",
    "\n",
    "تابع `GetLabels()` یک لیست از لیبل‌ها (برچسب‌های کلاس) برای فایل‌هایی که در آموزش مدل استفاده می‌شوند، تولید می‌کند.\n",
    "\n",
    "### 🎯 هدف:\n",
    "تشخیص این که هر فایل ورودی مربوط به **سیگنال (Signal)** است یا **پس‌زمینه (Background)**.\n",
    "\n",
    "### 📥 ورودی:\n",
    "- این تابع ورودی مستقیم ندارد، بلکه از مقادیر موجود در کلاس `Config` استفاده می‌کند:\n",
    "  - `Config.SIGNALS`: لیست فایل‌های مربوط به سیگنال (مثلاً WZ)\n",
    "  - `Config.BKGS`: لیست فایل‌های پس‌زمینه (مثلاً QCD)\n",
    "\n",
    "### 📤 خروجی:\n",
    "- یک لیست از اعداد صحیح (integers) با طول برابر با مجموع تعداد فایل‌های سیگنال و پس‌زمینه.\n",
    "  - عدد `1` برای فایل‌های سیگنال\n",
    "  - عدد `0` برای فایل‌های پس‌زمینه\n",
    "\n",
    "### 🧠 منطق عملکرد:\n",
    "1. برای هر فایل در `Config.SIGNALS`، مقدار ۱ به لیست اضافه می‌شود.\n",
    "2. برای هر فایل در `Config.BKGS`، مقدار ۰ به لیست اضافه می‌شود.\n",
    "3. ترتیب لیبل‌ها دقیقاً با ترتیب فایل‌ها در تابع `AllFiles()` همخوانی دارد، تا هنگام بارگذاری در Dataset دچار mismatch نشویم.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e853713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AllFiles():\n",
    "    ret = []\n",
    "    for signal in Config.SIGNALS:\n",
    "        ret.append(Path(Config.SIGNALS_PATH) / signal)\n",
    "    for bkg in Config.BKGS:\n",
    "        ret.append(Path(Config.BKG_PATH) / bkg)\n",
    "    return ret\n",
    "def GetLabels():\n",
    "    labels = []\n",
    "    for signal in Config.SIGNALS:\n",
    "        labels.append(1)  # Signal class\n",
    "    for bkg in Config.BKGS:\n",
    "        labels.append(0)  # Background class\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e24e36",
   "metadata": {},
   "source": [
    "## 🖼️ تابع `create_image` — ساخت تصویر دوبعدی از جت بر اساس ویژگی‌های مؤلفه‌ها\n",
    "\n",
    "این تابع وظیفه دارد با استفاده از ویژگی‌های ذرات تشکیل‌دهنده‌ی یک جت (مانند `pt`, `mass`, `charge`, `eta`, و `phi`) یک **نقشه حرارتی دوبعدی** (تصویر) از جت ایجاد کند. این تصویر می‌تواند برای ورودی مدل‌های یادگیری عمیق (به‌ویژه CNN) استفاده شود.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 هدف:\n",
    "تبدیل اطلاعات فیزیکی جت به یک تصویر ۲D با سه کانال (RGB)، جایی که:\n",
    "- کانال قرمز (R): شدت `pt` هر سلول،\n",
    "- کانال سبز (G): جرم `mass` هر سلول،\n",
    "- کانال آبی (B): مجموع `charge` ذرات در هر سلول.\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ ورودی‌ها:\n",
    "| نام متغیر | نوع داده | توضیح |\n",
    "|----------|----------|-------|\n",
    "| `pt`     | `np.array` | آرایه‌ی `pt` مؤلفه‌های جت |\n",
    "| `mass`   | `np.array` | جرم مؤلفه‌ها |\n",
    "| `charge` | `np.array` | بار الکتریکی مؤلفه‌ها |\n",
    "| `eta`    | `np.array` | موقعیت pseudorapidity |\n",
    "| `phi`    | `np.array` | موقعیت زاویه‌ای |\n",
    "| `size`   | `int`      | اندازه تصویر خروجی (تعداد پیکسل‌ها در هر محور)\n",
    "\n",
    "---\n",
    "\n",
    "### 🧮 مراحل پردازش:\n",
    "\n",
    "1. **ساخت تصویر خام**:\n",
    "   - ایجاد آرایه صفر با ابعاد `(size, size, 3)` برای ذخیره مقادیر `pt`, `mass`, `charge` در سه کانال RGB.\n",
    "\n",
    "2. **نرمال‌سازی مقادیر `eta` و `phi` به فضای تصویر**:\n",
    "   - `eta` به بازه `[0, size-1]` نگاشت می‌شود.\n",
    "   - `phi` ابتدا به بازه `(-π, π]` نگاشت شده و سپس به `[0, size-1]`.\n",
    "\n",
    "3. **انباشتن ویژگی‌ها در مختصات پیکسلی**:\n",
    "   - برای هر مؤلفه جت، اگر `pt > 0` باشد:\n",
    "     - مختصات تصویری آن محاسبه شده و در هر کانال مقدار مربوطه افزوده می‌شود.\n",
    "\n",
    "4. **نرمال‌سازی نهایی تصویر**:\n",
    "   - هر کانال جداگانه طوری نرمال می‌شود که حداکثر مقدار آن ۱ شود. این کار به شبکه کمک می‌کند بهتر یاد بگیرد.\n",
    "\n",
    "---\n",
    "\n",
    "### 📤 خروجی:\n",
    "یک آرایه‌ی `numpy` با ابعاد `(size, size, 3)` که نمایانگر تصویر ویژگی‌های جت در صفحه `η-φ` است. این تصویر برای ورودی به CNN آماده است.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 نکته علمی:\n",
    "استفاده از `η` و `φ` به‌جای مختصات دکارتی، به ما این امکان را می‌دهد که نمایشی زاویه‌ای و نسبی از ذرات درون جت داشته باشیم، مشابه تصویری که آشکارسازهای ذرات ثبت می‌کنند.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dce2b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(pt, mass , charge , eta, phi, size):\n",
    "    image = np.zeros((size, size , 3), dtype=np.float32)\n",
    "\n",
    "    min_eta = np.min(eta)\n",
    "    max_eta = np.max(eta)\n",
    "    phi = np.mod(phi + np.pi, 2 * np.pi) - np.pi\n",
    "\n",
    "    eta_idx = (((eta - min_eta) / (max_eta - min_eta)) * (size - 1)).astype(int)\n",
    "    phi_idx = (((phi + np.pi) / (2 * np.pi)) * (size - 1)).astype(int)\n",
    "\n",
    "    for i in range(len(pt)):\n",
    "        if pt[i] > 0:\n",
    "            x, y = eta_idx[i], phi_idx[i]\n",
    "            image[y, x , 0] += pt[i]\n",
    "            image[y, x , 1] += mass[i]\n",
    "            image[y, x , 2] += charge[i]\n",
    "    \n",
    "    image[:,:,0] /= np.max(image[:,:,0]) if np.max(image[:,:,0]) > 0 else 1\n",
    "    image[:,:,1] /= np.max(image[:,:,1]) if np.max(image[:,:,1]) > 0 else 1\n",
    "    image[:,:,2] /= np.max(image[:,:,2]) if np.max(image[:,:,2]) > 0 else 1\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1bf1ea",
   "metadata": {},
   "source": [
    "## کلاس `JetImageDataset`\n",
    "\n",
    "### پارامترهای ورودی سازنده (`__init__`)\n",
    "\n",
    "| پارامتر      | نوع داده         | توضیح                                                      |\n",
    "|--------------|------------------|------------------------------------------------------------|\n",
    "| `h5_paths`   | `list`           | لیست مسیر فایل‌های HDF5 که داده‌های جت را نگه می‌دارند.  |\n",
    "| `labels`     | `list`           | لیست برچسب‌های مربوط به هر فایل (0 برای پس‌زمینه، 1 برای سیگنال). |\n",
    "| `image_size` | `int`            | اندازه تصویر ساخته شده (مثلاً 32 برای تصویر 32×32 پیکسل). |\n",
    "| `n_jets`     | `int` (اختیاری)  | تعداد جت‌هایی که باید از هر فایل خوانده شود؛ `-1` برای خواندن همه. |\n",
    "\n",
    "---\n",
    "\n",
    "### متغیرهای داخلی (attributes)\n",
    "\n",
    "| نام متغیر       | نوع داده             | توضیح                                                                                       |\n",
    "|-----------------|----------------------|---------------------------------------------------------------------------------------------|\n",
    "| `self.pt`       | `numpy.ndarray`      | آرایه‌ای شامل مقدار `pt` مؤلفه‌های جت‌ها برای همه نمونه‌ها.                               |\n",
    "| `self.eta`      | `numpy.ndarray`      | آرایه‌ای شامل مقدار η (eta) مؤلفه‌های جت‌ها برای همه نمونه‌ها.                            |\n",
    "| `self.phi`      | `numpy.ndarray`      | آرایه‌ای شامل مقدار φ (phi) مؤلفه‌های جت‌ها برای همه نمونه‌ها.                            |\n",
    "| `self.mass`     | `numpy.ndarray`      | آرایه‌ای شامل جرم مؤلفه‌های جت‌ها برای همه نمونه‌ها.                                     |\n",
    "| `self.charge`   | `numpy.ndarray`      | آرایه‌ای شامل بار الکتریکی مؤلفه‌های جت‌ها برای همه نمونه‌ها.                            |\n",
    "| `self.labels`   | `numpy.ndarray`      | آرایه برچسب‌ها (labels) که کلاس هر جت را مشخص می‌کند.                                     |\n",
    "| `self.image_size`| `int`                | اندازه‌ی تصویر (طول و عرض به پیکسل) که برای هر نمونه ساخته می‌شود.                        |\n",
    "\n",
    "---\n",
    "\n",
    "## متدها\n",
    "\n",
    "### `__init__(self, h5_paths, labels, image_size, n_jets=-1)`\n",
    "\n",
    "- سازنده کلاس.\n",
    "- وظیفه بارگذاری داده‌ها از فایل‌های HDF5 و آماده‌سازی آرایه‌های ویژگی‌ها و برچسب‌ها.\n",
    "- بررسی وجود فایل‌ها و بارگذاری مؤلفه‌های جت: `pt`, `eta`, `phi`, `mass`, `charge`.\n",
    "- الحاق داده‌ها از چند فایل به صورت پشت سر هم.\n",
    "\n",
    "---\n",
    "\n",
    "### `__len__(self)`\n",
    "\n",
    "- بازگشت تعداد کل نمونه‌ها (تعداد جت‌ها).\n",
    "- پیاده‌سازی شده تا با `DataLoader`های PyTorch سازگار باشد.\n",
    "- امضا:  \n",
    "  ```python\n",
    "  def __len__(self):\n",
    "      return len(self.pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9c85d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JetImageDataset(Dataset):\n",
    "    def __init__(self, h5_paths, labels , image_size  , n_jets = -1):\n",
    "        super(JetImageDataset, self).__init__()\n",
    "\n",
    "        self.pt = None\n",
    "        self.eta = None\n",
    "        self.phi = None\n",
    "        self.mass = None\n",
    "        self.charge = None\n",
    "        self.labels = np.array([])\n",
    "        for h5_path , lbl in zip(h5_paths, labels):\n",
    "            if not Path(h5_path).exists():\n",
    "                raise FileNotFoundError(f\"File {h5_path} does not exist.\")\n",
    "            with h5py.File(h5_path, 'r') as f:\n",
    "                cnsts = f[\"objects/jets/jet1_cnsts\"][:n_jets]\n",
    "                #jets = f[\"objects/jets/jet1_obs\"][:n_jets]\n",
    "                if self.pt is None:\n",
    "                    self.pt = cnsts[:,:,0]\n",
    "                    self.eta = cnsts[:,:,1]\n",
    "                    self.phi = cnsts[:,:,2]\n",
    "                    self.mass = cnsts[:,:,3]\n",
    "                    self.charge = cnsts[:,:,4]\n",
    "                else:\n",
    "                    self.pt = np.concatenate( [self.pt ,  cnsts[:,:,0]] )\n",
    "                    self.eta = np.concatenate( [self.eta ,  cnsts[:,:,1]] )\n",
    "                    self.phi = np.concatenate( [self.phi ,  cnsts[:,:,2]] )\n",
    "                    self.mass = np.concatenate( [self.mass ,  cnsts[:,:,3]] )\n",
    "                    self.charge = np.concatenate( [self.charge ,  cnsts[:,:,4]] )\n",
    "\n",
    "                njets = cnsts.shape[0]\n",
    "                self.labels = np.concatenate( [self.labels , np.full(njets, lbl)] )\n",
    "        \n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pt)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = create_image(\n",
    "        self.pt[idx],\n",
    "        self.mass[idx],\n",
    "        self.charge[idx],\n",
    "        self.eta[idx],\n",
    "        self.phi[idx],\n",
    "        self.image_size\n",
    "    )\n",
    "        image = np.transpose(image, (2, 0, 1))  # تبدیل [H, W, C] به [C, H, W]\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12ba942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = JetImageDataset( AllFiles(), GetLabels(), Config.IMAGE_SIZE, n_jets=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d752dd73",
   "metadata": {},
   "source": [
    "### نمایش به واسطه کلاس matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93e81c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f76d8fcf820>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow( j[120][0][0,:,:,:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68db67",
   "metadata": {},
   "source": [
    "## کلاس `CNNClassifier`\n",
    "\n",
    "این کلاس یک مدل شبکه عصبی پیچشی (CNN) ساده برای دسته‌بندی دو کلاس (مثل جت‌های WZ و QCD) تعریف می‌کند.  \n",
    "کلاس از `torch.nn.Module` ارث‌بری می‌کند و شامل چند لایه کانولوشن، فعال‌سازی، کاهش ابعاد و در نهایت لایه‌های خطی (Fully Connected) است.\n",
    "\n",
    "---\n",
    "\n",
    "## متدها و اجزای کلاس\n",
    "\n",
    "### 1. متد سازنده: `__init__(self, num_classes)`\n",
    "\n",
    "- ورودی:\n",
    "  - `num_classes` (int): تعداد کلاس‌های خروجی که مدل باید آنها را تشخیص دهد (مثلاً ۲ برای WZ و QCD).\n",
    "\n",
    "- کاری که انجام می‌دهد:\n",
    "  - با استفاده از `super()`، سازنده کلاس پدر (`nn.Module`) را فراخوانی می‌کند.\n",
    "  - سپس یک شبکه عصبی به صورت زنجیره‌ای (`nn.Sequential`) تعریف می‌کند که شامل چندین لایه است:\n",
    "\n",
    "#### ساختار لایه‌ها:\n",
    "\n",
    "| نوع لایه             | مشخصات                               | توضیح                                   |\n",
    "|----------------------|------------------------------------|----------------------------------------|\n",
    "| `nn.Conv2d(1, 16, kernel_size=3, padding=1)` | کانولوشن ۲ بعدی با ۱ کانال ورودی و ۱۶ فیلتر، هسته ۳×۳، padding=1 | استخراج ویژگی‌های اولیه از تصویر ورودی تک‌کاناله |\n",
    "| `nn.ReLU()`           | تابع فعال‌سازی ReLU                 | افزودن غیرخطی بودن                      |\n",
    "| `nn.MaxPool2d(2)`     | ماکس‌پولینگ با اندازه ۲×۲          | کاهش ابعاد فضایی به نصف در هر بعد      |\n",
    "| `nn.Conv2d(16, 32, kernel_size=3, padding=1)`| کانولوشن ۲ بعدی با ۱۶ کانال ورودی و ۳۲ فیلتر، هسته ۳×۳، padding=1 | استخراج ویژگی‌های پیچیده‌تر            |\n",
    "| `nn.ReLU()`           | تابع فعال‌سازی ReLU                 | افزودن غیرخطی بودن                      |\n",
    "| `nn.MaxPool2d(2)`     | ماکس‌پولینگ با اندازه ۲×۲          | کاهش دوباره ابعاد فضایی به نصف         |\n",
    "| `nn.Flatten()`        | صاف کردن (Flatten) داده‌ها         | تبدیل خروجی ۴ بعدی به بردار ۱ بعدی    |\n",
    "| `nn.Linear(32 * (Config.IMAGE_SIZE // 4) ** 2, 64)` | لایه خطی (Fully Connected) با ورودی متناسب با ابعاد خروجی از لایه‌های قبلی و 64 نورون خروجی | کاهش ابعاد و استخراج ترکیبات خطی ویژگی‌ها |\n",
    "| `nn.ReLU()`           | تابع فعال‌سازی ReLU                 | افزودن غیرخطی بودن                      |\n",
    "| `nn.Linear(64, num_classes)` | لایه خطی خروجی با تعداد نورون برابر تعداد کلاس‌ها | پیش‌بینی احتمال تعلق نمونه به هر کلاس |\n",
    "\n",
    "---\n",
    "\n",
    "### نکته درباره ابعاد\n",
    "\n",
    "- تصویر ورودی اندازه‌ای برابر با `Config.IMAGE_SIZE × Config.IMAGE_SIZE` دارد (مثلاً ۳۲×۳۲).\n",
    "- دو بار ماکس‌پولینگ با اندازه ۲ انجام شده، پس ابعاد بعد از کانولوشن‌ها کاهش می‌یابد به:  \n",
    "  \\[\n",
    "  \\frac{\\text{IMAGE_SIZE}}{2} \\to \\frac{\\text{IMAGE_SIZE}}{4}\n",
    "  \\]\n",
    "- تعداد کانال‌ها در آخرین لایه کانولوشن برابر ۳۲ است.\n",
    "- پس ابعاد ورودی لایه خطی برابر است با:  \n",
    "  \\[\n",
    "  32 \\times \\left(\\frac{\\text{IMAGE_SIZE}}{4}\\right)^2\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "### 2. متد `forward(self, x)`\n",
    "\n",
    "- ورودی:\n",
    "  - `x`: ورودی داده به مدل؛ معمولاً یک تنسور ۴ بعدی با ابعاد (batch_size, channels=1, height, width).\n",
    "  \n",
    "- عملکرد:\n",
    "  - داده ورودی را به مدل `self.net` می‌دهد تا به صورت مرحله‌به‌مرحله از لایه‌ها عبور کند.\n",
    "  - خروجی نهایی پیش‌بینی مدل برای هر نمونه است (تعداد نورون‌های خروجی برابر با تعداد کلاس‌ها).\n",
    "\n",
    "- امضا و پیاده‌سازی:  \n",
    "  ```python\n",
    "  def forward(self, x):\n",
    "      return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a5472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * (Config.IMAGE_SIZE // 4) ** 2, 64), nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc623ad",
   "metadata": {},
   "source": [
    "## توضیح کامل و مفصل تابع `train`\n",
    "\n",
    "تابع `train` مسئول آموزش مدل شبکه عصبی کانولوشنی (CNN) است که داده‌ها را به صورت دسته‌ای (batch) پردازش کرده، خطای مدل را در هر مرحله محاسبه می‌کند و با استفاده از الگوریتم بهینه‌سازی وزن‌های مدل را به‌روزرسانی می‌نماید. این روند به تعداد مشخصی دوره یا epoch تکرار می‌شود تا مدل به تدریج یادگیری خود را بهبود دهد.\n",
    "\n",
    "---\n",
    "## شرح جزئیات کد تابع train\n",
    "\n",
    "- `model.train()`  \n",
    "  مدل را در حالت آموزش قرار می‌دهد تا لایه‌هایی مثل Dropout و BatchNorm به درستی رفتار کنند.\n",
    "\n",
    "- `loss_history = []`  \n",
    "  لیستی برای ذخیره میانگین مقادیر loss در هر epoch جهت تحلیل روند آموزش.\n",
    "\n",
    "- `for epoch in range(epochs):`  \n",
    "  حلقه اصلی آموزش که به تعداد epoch مشخص شده، اجرا می‌شود.\n",
    "\n",
    "- `epoch_loss = 0`  \n",
    "  متغیری برای جمع‌آوری مجموع loss در هر epoch.\n",
    "\n",
    "- `for images, labels in loader:`  \n",
    "  حلقه روی batches داده‌های ورودی (تصاویر و برچسب‌ها) از DataLoader.\n",
    "\n",
    "- `images, labels = images.to(device), labels.to(device)`  \n",
    "  انتقال داده‌ها به دستگاه محاسباتی (CPU یا GPU).\n",
    "\n",
    "- `optimizer.zero_grad()`  \n",
    "  صفر کردن گرادیان‌های انباشته شده قبل از شروع backpropagation.\n",
    "\n",
    "- `outputs = model(images)`  \n",
    "  اجرای مدل روی تصاویر برای بدست آوردن پیش‌بینی‌ها.\n",
    "\n",
    "- `loss = criterion(outputs, labels)`  \n",
    "  محاسبه مقدار تابع خطا (Loss) بین پیش‌بینی مدل و برچسب‌های واقعی.\n",
    "\n",
    "- `loss.backward()`  \n",
    "  محاسبه گرادیان‌ها نسبت به پارامترهای مدل با الگوریتم backpropagation.\n",
    "\n",
    "- `optimizer.step()`  \n",
    "  به‌روزرسانی وزن‌های مدل بر اساس گرادیان‌ها.\n",
    "\n",
    "- `epoch_loss += loss.item()`  \n",
    "  جمع‌آوری مقدار عددی loss برای میانگین‌گیری در انتهای epoch.\n",
    "\n",
    "- `avg_loss = epoch_loss / len(loader)`  \n",
    "  محاسبه میانگین loss در کل batchهای یک epoch.\n",
    "\n",
    "- `loss_history.append(avg_loss)`  \n",
    "  ذخیره میانگین loss هر epoch برای تحلیل روند آموزش.\n",
    "\n",
    "- `print(f\"[Epoch {epoch+1}/{epochs}] Loss: {avg_loss:.4f}\")`  \n",
    "  نمایش مقدار loss هر epoch به صورت زنده.\n",
    "\n",
    "- `return loss_history`  \n",
    "  بازگرداندن لیست مقادیر loss برای بررسی و رسم نمودار کاهش خطا.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dafc07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, epochs, device):\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(loader)\n",
    "        loss_history.append(avg_loss)\n",
    "        print(f\"[Epoch {epoch+1}/{epochs}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return loss_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d85c35",
   "metadata": {},
   "source": [
    "## توضیح تابع `plot_losses`\n",
    "\n",
    "- `plt.figure(figsize=(8, 5))`  \n",
    "  ایجاد یک شکل (figure) با اندازه ۸ در ۵ اینچ برای ترسیم نمودار.\n",
    "\n",
    "- `plt.plot(losses, marker='o')`  \n",
    "  رسم نمودار خطی از داده‌های `losses` که معمولاً مقادیر خطای آموزش در هر epoch هستند.  \n",
    "  پارامتر `marker='o'` باعث می‌شود هر نقطه داده با دایره نمایش داده شود.\n",
    "\n",
    "- `plt.title(\"Training Loss\")`  \n",
    "  اضافه کردن عنوان \"Training Loss\" به نمودار.\n",
    "\n",
    "- `plt.xlabel(\"Epoch\")`  \n",
    "  برچسب محور افقی (x-axis) به نام \"Epoch\" که تعداد دوره‌های آموزش را نشان می‌دهد.\n",
    "\n",
    "- `plt.ylabel(\"Loss\")`  \n",
    "  برچسب محور عمودی (y-axis) به نام \"Loss\" که مقدار خطا را نشان می‌دهد.\n",
    "\n",
    "- `plt.grid(True)`  \n",
    "  فعال کردن خطوط شبکه‌ای (grid) در پس‌زمینه نمودار برای خوانایی بهتر.\n",
    "\n",
    "- `plt.show()`  \n",
    "  نمایش نمودار رسم شده به کاربر.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(losses, marker='o')\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346cf94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = JetImageDataset( AllFiles(), GetLabels(), Config.IMAGE_SIZE, n_jets=100)\n",
    "dataloader = DataLoader(dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = CNNClassifier(Config.NUM_CLASSES).to(Config.DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=Config.LR)\n",
    "\n",
    "losses = train(model, dataloader, criterion, optimizer, Config.EPOCHS, Config.DEVICE)\n",
    "\n",
    "plot_losses(losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d184e2d",
   "metadata": {},
   "source": [
    "## جمع‌بندی نهایی درس: طراحی و آموزش شبکه عصبی کانولوشنی برای تشخیص جت‌ها در فیزیک ذرات\n",
    "\n",
    "دانشجویان گرامی،\n",
    "\n",
    "در این دوره، ما قدم به قدم با یک مسئله عملی در فیزیک ذرات آشنا شدیم: تشخیص دسته‌بندی جت‌های WZ و QCD با استفاده از داده‌های پیچیده آزمایشگاهی. هدف اصلی ما توسعه یک مدل یادگیری عمیق مبتنی بر شبکه‌های عصبی کانولوشنی (CNN) بود که بتواند تصاویر بازنمایی شده از ویژگی‌های فیزیکی ذرات را به درستی دسته‌بندی کند.\n",
    "\n",
    "---\n",
    "\n",
    "## مرور کلی مراحل انجام شده\n",
    "\n",
    "### 1. آماده‌سازی و تنظیمات اولیه  \n",
    "- تعریف یک کلاس `Config` جامع برای مدیریت پارامترهای پروژه شامل مسیر داده‌ها، نام فایل‌ها، اندازه تصاویر، پارامترهای آموزش و دستگاه اجرا.\n",
    "\n",
    "### 2. مدیریت داده‌ها  \n",
    "- توابع `AllFiles` و `GetLabels` برای بارگذاری لیست فایل‌های داده و برچسب‌های مربوط به سیگنال و پس‌زمینه.  \n",
    "- بارگذاری داده‌ها از فرمت HDF5 و استخراج ویژگی‌های فیزیکی ذرات.\n",
    "\n",
    "### 3. تبدیل داده‌ها به تصاویر  \n",
    "- طراحی تابع `create_image` که ویژگی‌های مهم هر ذره (مانند پی‌تی، جرم، بار) را به صورت نقشه حرارتی سه کاناله در مختصات η و φ مدل‌سازی می‌کند.  \n",
    "- این مرحله، داده‌های عددی پیچیده را به قالبی تبدیل می‌کند که شبکه‌های کانولوشنی بتوانند به خوبی روی آن آموزش ببینند.\n",
    "\n",
    "### 4. ساخت دیتاست سفارشی  \n",
    "- ایجاد کلاس `JetImageDataset` که داده‌ها را از فایل‌ها خوانده، تصاویر ساخته و برچسب‌ها را به آنها متصل می‌کند.  \n",
    "- پیاده‌سازی سازگاری با PyTorch DataLoader برای مدیریت داده‌ها به صورت بچ‌های آموزشی.\n",
    "\n",
    "### 5. تعریف مدل CNN  \n",
    "- طراحی معماری CNN ساده ولی موثر شامل لایه‌های کانولوشن، لایه‌های Pooling، فعال‌سازی ReLU و لایه‌های کاملاً متصل برای دسته‌بندی دو کلاسه.  \n",
    "- آموزش مدل روی داده‌های ورودی تصویر.\n",
    "\n",
    "### 6. فرایند آموزش  \n",
    "- تعریف تابع `train` که فرایند آموزش مدل را با محاسبه گرادیان، به‌روزرسانی وزن‌ها و محاسبه خطای میانگین در هر epoch مدیریت می‌کند.  \n",
    "- نمایش روند کاهش خطا در طول دوره‌های آموزش.\n",
    "\n",
    "### 7. ارزیابی و مشاهده روند آموزش  \n",
    "- رسم نمودار تغییرات خطا با تابع `plot_losses` برای بررسی بصری و اطمینان از روند یادگیری مناسب مدل.\n",
    "\n",
    "---\n",
    "\n",
    "## نکات کلیدی و توصیه‌های پایانی\n",
    "\n",
    "- **نرمال‌سازی داده‌ها** و تبدیل ویژگی‌های فیزیکی به تصاویر سه‌کاناله باعث شده مدل CNN بتواند الگوهای مکانی-ویژگی را به خوبی یاد بگیرد.  \n",
    "- **ساخت دیتاست دقیق** و مدیریت برچسب‌ها گام بسیار مهمی در تضمین صحت آموزش و ارزیابی مدل بود.  \n",
    "- استفاده از **PyTorch** امکانات زیادی برای مدیریت داده، تعریف شبکه و فرایند آموزش فراهم می‌کند که باعث می‌شود مدل‌سازی پیچیده به شکل ساختاریافته و قابل فهم انجام شود.  \n",
    "- این پروژه نمونه‌ی خوبی برای درک عمیق کاربرد یادگیری عمیق در فیزیک و تبدیل داده‌های پیچیده علمی به مسائل قابل حل در حوزه هوش مصنوعی است.\n",
    "\n",
    "---\n",
    "\n",
    "## سخن پایانی\n",
    "\n",
    "یادگیری و بکارگیری شبکه‌های عصبی کانولوشنی در داده‌های فیزیکی، پلی میان علم داده و فیزیک مدرن است. این توانایی به ما کمک می‌کند که نه تنها درک بهتری از داده‌ها داشته باشیم، بلکه به کشف‌های نوین و تحلیل‌های دقیق‌تر در حوزه فیزیک ذرات برسیم.\n",
    "\n",
    "به عنوان استاد این درس، از تمام تلاش و دقت شما سپاسگزارم و امیدوارم دانش و مهارت‌های آموخته شده را در پروژه‌ها و تحقیقات آینده به کار گیرید و همچنان با شور و اشتیاق به سمت دانش عمیق‌تر و کاربردی‌تر پیش بروید.\n",
    "\n",
    "موفق و پیروز باشید!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086491dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
